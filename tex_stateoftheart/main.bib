%! Author = pierre
%! Date = 16/04/2024

@article{ref1,
    author = {Zonghan Wu and
 Shirui Pan and
 Fengwen Chen and
 Guodong Long and
 Chengqi Zhang and
 Philip S. Yu},
    title = {A Comprehensive Survey on Graph Neural Networks},
    journal = {CoRR},
    volume = {abs/1901.00596},
    year = {2019},
    url = {http://arxiv.org/abs/1901.00596},
    eprinttype = {arXiv},
    eprint = {1901.00596},
    timestamp = {Sat, 30 Sep 2023 10:08:11 +0200},
    biburl = {https://dblp.org/rec/journals/corr/abs-1901-00596.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ref2,
    author = {Derrow-Pinion, Austin and She, Jennifer and Wong, David and Lange, Oliver and Hester, Todd and Perez, Luis and Nunkesser, Marc and Lee, Seongjae and Guo, Xueying and Wiltshire, Brett and Battaglia, Peter W. and Gupta, Vishal and Li, Ang and Xu, Zhongwen and Sanchez-Gonzalez, Alvaro and Li, Yujia and Velickovic, Petar},
    title = {ETA Prediction with Graph Neural Networks in Google Maps},
    year = {2021},
    isbn = {9781450384469},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3459637.3481916},
    doi = {10.1145/3459637.3481916},
    abstract = {Travel-time prediction constitutes a task of high importance in transportation networks, with web mapping services like Google Maps regularly serving vast quantities of travel time queries from users and enterprises alike. Further, such a task requires accounting for complex spatiotemporal interactions (modelling both the topological properties of the road network and anticipating events---such as rush hours---that may occur in the future). Hence, it is an ideal target for graph representation learning at scale. Here we present a graph neural network estimator for estimated time of arrival (ETA) which we have deployed in production at Google Maps. While our main architecture consists of standard GNN building blocks, we further detail the usage of training schedule methods such as MetaGradients in order to make our model robust and production-ready. We also provide prescriptive studies: ablating on various architectural decisions and training regimes, and qualitative analyses on real-world situations where our model provides a competitive edge. Our GNN proved powerful when deployed, significantly reducing negative ETA outcomes in several regions compared to the previous production baseline (40+\% in cities like Sydney).},
    booktitle = {Proceedings of the 30th ACM International Conference on Information \& Knowledge Management},
    pages = {3767–3776},
    numpages = {10},
    keywords = {metagradients, graph neural networks, google maps},
    location = {Virtual Event, Queensland, Australia},
    series = {CIKM '21}
}

@inproceedings{ref3,
    author = {Benedek Rozemberczki and Paul Scherer and Yixuan He and George Panagopoulos and Alexander Riedel and Maria Astefanoaei and Oliver Kiss and Ferenc Beres and Guzman Lopez and Nicolas Collignon and Rik Sarkar},
    title = {{PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models}},
    year = {2021},
    booktitle = {Proceedings of the 30th ACM International Conference on Information and Knowledge Management},
    pages = {4564–4573},
}

@inproceedings{ref4,
    title = {The Network Data Repository with Interactive Graph Analytics and Visualization},
    author = {Ryan A. Rossi and Nesreen K. Ahmed},
    booktitle = {AAAI},
    url = {https://networkrepository.com},
    year = {2015}
}

@misc{ref5,
    title = {GaAN: Gated Attention Networks for Learning on Large and Spatiotemporal Graphs},
    author = {Jiani Zhang and Xingjian Shi and Junyuan Xie and Hao Ma and Irwin King and Dit-Yan Yeung},
    year = {2018},
    eprint = {1803.07294},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG}
}

@misc{ref6,
    title = {Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting},
    author = {Yaguang Li and Rose Yu and Cyrus Shahabi and Yan Liu},
    year = {2018},
    eprint = {1707.01926},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG}
}

@inproceedings{ref7,
    series = {IJCAI-2018},
    title = {Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting},
    url = {http://dx.doi.org/10.24963/ijcai.2018/505},
    DOI = {10.24963/ijcai.2018/505},
    booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence},
    publisher = {International Joint Conferences on Artificial Intelligence Organization},
    author = {Yu, Bing and Yin, Haoteng and Zhu, Zhanxing},
    year = {2018},
    month = jul, collection = {IJCAI-2018}
}

@Article{ref8,
AUTHOR = {Perera, Jeewaka and Liu, Shih-Hsi and Mernik, Marjan and Črepinšek, Matej and Ravber, Miha},
TITLE = {A Graph Pointer Network-Based Multi-Objective Deep Reinforcement Learning Algorithm for Solving the Traveling Salesman Problem},
JOURNAL = {Mathematics},
VOLUME = {11},
YEAR = {2023},
NUMBER = {2},
ARTICLE-NUMBER = {437},
URL = {https://www.mdpi.com/2227-7390/11/2/437},
ISSN = {2227-7390},
ABSTRACT = {Traveling Salesman Problems (TSPs) have been a long-lasting interesting challenge to researchers in different areas. The difficulty of such problems scales up further when multiple objectives are considered concurrently. Plenty of work in evolutionary algorithms has been introduced to solve multi-objective TSPs with promising results, and the work in deep learning and reinforcement learning has been surging. This paper introduces a multi-objective deep graph pointer network-based reinforcement learning (MODGRL) algorithm for multi-objective TSPs. The MODGRL improves an earlier multi-objective deep reinforcement learning algorithm, called DRL-MOA, by utilizing a graph pointer network to learn the graphical structures of TSPs. Such improvements allow MODGRL to be trained on a small-scale TSP, but can find optimal solutions for large scale TSPs. NSGA-II, MOEA/D and SPEA2 are selected to compare with MODGRL and DRL-MOA. Hypervolume, spread and coverage over Pareto front (CPF) quality indicators were selected to assess the algorithms’ performance. In terms of the hypervolume indicator that represents the convergence and diversity of Pareto-frontiers, MODGRL outperformed all the competitors on the three well-known benchmark problems. Such findings proved that MODGRL, with the improved graph pointer network, indeed performed better, measured by the hypervolume indicator, than DRL-MOA and the three other evolutionary algorithms. MODGRL and DRL-MOA were comparable in the leading group, measured by the spread indicator. Although MODGRL performed better than DRL-MOA, both of them were just average regarding the evenness and diversity measured by the CPF indicator. Such findings remind that different performance indicators measure Pareto-frontiers from different perspectives. Choosing a well-accepted and suitable performance indicator to one’s experimental design is very critical, and may affect the conclusions. Three evolutionary algorithms were also experimented on with extra iterations, to validate whether extra iterations affected the performance. The results show that NSGA-II and SPEA2 were greatly improved measured by the Spread and CPF indicators. Such findings raise fairness concerns on algorithm comparisons using different fixed stopping criteria for different algorithms, which appeared in the DRL-MOA work and many others. Through these lessons, we concluded that MODGRL indeed performed better than DRL-MOA in terms of hypervolumne, and we also urge researchers on fair experimental designs and comparisons, in order to derive scientifically sound conclusions.},
DOI = {10.3390/math11020437}
}